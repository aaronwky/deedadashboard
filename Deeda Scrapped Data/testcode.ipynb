{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\hua an\\appdata\\roaming\\python\\python311\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x004A6AB3+25587]\n\t(No symbol) [0x00439C54]\n\t(No symbol) [0x00332113]\n\t(No symbol) [0x0030E23B]\n\t(No symbol) [0x003A179F]\n\t(No symbol) [0x003B4CB9]\n\t(No symbol) [0x0039A936]\n\t(No symbol) [0x0036BA73]\n\t(No symbol) [0x0036C4CD]\n\tGetHandleVerifier [0x00784C63+3032483]\n\tGetHandleVerifier [0x007D6B99+3368153]\n\tGetHandleVerifier [0x00538F62+624802]\n\tGetHandleVerifier [0x005407DC+655644]\n\t(No symbol) [0x0044260D]\n\t(No symbol) [0x0043F6D8]\n\t(No symbol) [0x0043F875]\n\t(No symbol) [0x00431CA6]\n\tBaseThreadInitThunk [0x76087BA9+25]\n\tRtlInitializeExceptionChain [0x7752C11B+107]\n\tRtlClearBits [0x7752C09F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Parse the page source with BeautifulSoup\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Click to see more replies\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m button \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaper-button#more-replies\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=129.0.6668.70)\nStacktrace:\n\tGetHandleVerifier [0x004A6AB3+25587]\n\t(No symbol) [0x00439C54]\n\t(No symbol) [0x00332113]\n\t(No symbol) [0x0030E23B]\n\t(No symbol) [0x003A179F]\n\t(No symbol) [0x003B4CB9]\n\t(No symbol) [0x0039A936]\n\t(No symbol) [0x0036BA73]\n\t(No symbol) [0x0036C4CD]\n\tGetHandleVerifier [0x00784C63+3032483]\n\tGetHandleVerifier [0x007D6B99+3368153]\n\tGetHandleVerifier [0x00538F62+624802]\n\tGetHandleVerifier [0x005407DC+655644]\n\t(No symbol) [0x0044260D]\n\t(No symbol) [0x0043F6D8]\n\t(No symbol) [0x0043F875]\n\t(No symbol) [0x00431CA6]\n\tBaseThreadInitThunk [0x76087BA9+25]\n\tRtlInitializeExceptionChain [0x7752C11B+107]\n\tRtlClearBits [0x7752C09F+191]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Initialize the WebDriver\n",
    "from selenium.webdriver.chrome.service import Service  # Add this import\n",
    "\n",
    "# Download and set up the ChromeDriver\n",
    "chrome_driver_path = ChromeDriverManager().install()\n",
    "service = Service(chrome_driver_path)  # Update this line\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Open the YouTube video\n",
    "driver.get(video_to_scrape)\n",
    "\n",
    "# Scroll down to load comments\n",
    "for _ in range(20):  # Adjust the range to load more comments\n",
    "    ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "    time.sleep(1)\n",
    "\n",
    "# Parse the page source with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# Click to see more replies\n",
    "for button in soup.select('paper-button#more-replies'):\n",
    "    driver.execute_script(\"arguments[0].click();\", button)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Stop scrolling if the number of comments matches the count-text\n",
    "comment_count_text = soup.select_one('yt-formatted-string.count-text').text.strip()\n",
    "total_comments = int(comment_count_text.split()[0].replace(',', ''))\n",
    "\n",
    "if len(soup.select('#content-text')) >= total_comments:\n",
    "    break\n",
    "# Extract comments\n",
    "comments = []\n",
    "for comment in soup.select('#content-text'):\n",
    "    user_id = comment.find_previous('a', {'id': 'author-text'}).span.text.strip()\n",
    "    published_datetime = comment.find_previous('yt-formatted-string', {'class': 'published-time-text'}).a.text.strip()\n",
    "    likes = comment.find_previous('span', {'id': 'vote-count-middle'}).text.strip()\n",
    "    comment_text = comment.text.strip()\n",
    "    \n",
    "    comments.append({\n",
    "        'user_id': user_id,\n",
    "        'published_datetime': published_datetime,\n",
    "        'likes': likes,\n",
    "        'comment_text': comment_text\n",
    "    })\n",
    "\n",
    "# Save comments to a JSON file\n",
    "with open('comments.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(comments, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "# BEGIN: Additional Scrolling and Stopping Condition\n",
    "# Scroll down to load more comments until the specified number is reached\n",
    "target_comment_count = 37\n",
    "current_comment_count = 0\n",
    "\n",
    "while current_comment_count < target_comment_count:\n",
    "    ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    current_comment_count = len(soup.select('#content-text'))\n",
    "    print(f\"Current comment count: {current_comment_count}\")\n",
    "\n",
    "print(\"Reached the target number of comments.\")\n",
    "# END: Additional Scrolling and Stopping Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment count: Not found\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Initialize the WebDriver\n",
    "from selenium.webdriver.chrome.service import Service  # Add this import\n",
    "\n",
    "# Download and set up the ChromeDriver\n",
    "chrome_driver_path = ChromeDriverManager().install()\n",
    "service = Service(chrome_driver_path)  # Update this line\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "# Open the YouTube video\n",
    "video_to_scrape = \"https://www.youtube.com/watch?v=Zn6-3gp8pKg\" # Provide YT Video URL\n",
    "\n",
    "driver.get(video_to_scrape)\n",
    "# Scroll down to load comments\n",
    "for _ in range(1):  # Adjust the range to load more comments\n",
    "    ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "    time.sleep(1)\n",
    "# Load the YouTube page using BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Get the variable using the provided CSS selector\n",
    "comment_count_element = soup.select_one('#count yt-formatted-string span:nth-child(1)')\n",
    "comment_count = comment_count_element.text if comment_count_element else 'Not found'\n",
    "\n",
    "print(f\"Comment count: {comment_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"1b319a6c7164580b6d21eaafbfe23d0c\", element=\"f.F34D633F4D765CD76C4686109436B562.d.719D9F57577030E0F562BC4FD980A60A.e.97\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1b319a6c7164580b6d21eaafbfe23d0c\", element=\"f.F34D633F4D765CD76C4686109436B562.d.719D9F57577030E0F562BC4FD980A60A.e.98\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"1b319a6c7164580b6d21eaafbfe23d0c\", element=\"f.F34D633F4D765CD76C4686109436B562.d.719D9F57577030E0F562BC4FD980A60A.e.99\")>]\n",
      "click  0\n",
      "click  1\n",
      "click  2\n",
      "Extracting comments...\n",
      "0  : {'username': '@BlindGardener', 'comment': 'I like that you actually tried to pronounce the names correctly without American accent.', 'likes': '37', 'dates': '5 years ago'}\n",
      "1  : {'username': '@Emma88178', 'comment': 'Yeah the Midwest accent can be annoying some times. But this man is not American…', 'likes': '', 'dates': '3 years ago'}\n",
      "2  : {'username': '@parichehrmanuchehrkhodayaa5405', 'comment': 'Dog is God Angel in fur Thank you very much  Excellent delightful video ', 'likes': '1', 'dates': '5 years ago'}\n",
      "3  : {'username': '@virginiatrujillo3717', 'comment': 'Where does  shiatsu dog come from?', 'likes': '1', 'dates': '5 years ago'}\n",
      "4  : {'username': '@yukijiconan9917', 'comment': 'My grandparents (in Japan) had a Japanese terrier. Miss him so much \\nI never had dogs before but I would love to have an akita one day', 'likes': '15', 'dates': '5 years ago'}\n",
      "5  : {'username': '@CosmicNerdStudios', 'comment': \"The Kai dog is genuinely my absolute favorite type of dog. They're so cool both in their history and appearance, and their temperament.\", 'likes': '6', 'dates': '4 years ago'}\n",
      "6  : {'username': '@blazinvenus3914', 'comment': \"I have an amazing sweetheart of a besty Poochin!  Had a Chin growing up such sweet dog's!\", 'likes': '6', 'dates': '5 years ago'}\n",
      "7  : {'username': '@catmagic2226', 'comment': 'I want a Japanese chin love them.', 'likes': '4', 'dates': '4 years ago'}\n",
      "8  : {'username': '@nadiawasfi5458', 'comment': 'Wow 0 dislikes good job animalwised', 'likes': '4', 'dates': '5 years ago'}\n",
      "9  : {'username': '@barshapatra2750', 'comment': 'And a lot among them look so similar ', 'likes': '3', 'dates': '3 years ago'}\n",
      "10  : {'username': '@aurora_boketto7746', 'comment': 'I want a Japese spitz so baddd ', 'likes': '4', 'dates': '3 years ago'}\n",
      "11  : {'username': '@cursedexno2956', 'comment': 'One of my neighbors actually had a tosa inu and he was very affectionate and friendly ', 'likes': '2', 'dates': '3 years ago'}\n",
      "12  : {'username': '@raikynovianto4492', 'comment': 'I love Japanese Spitz', 'likes': '1', 'dates': '1 year ago'}\n",
      "13  : {'username': '@norwayspotter26', 'comment': 'Shiba inu ️', 'likes': '3', 'dates': '5 years ago'}\n",
      "14  : {'username': '@akitainumato9458', 'comment': '️', 'likes': '3', 'dates': '5 years ago'}\n",
      "15  : {'username': '@CyberMoth_', 'comment': 'Ive always wanted a japanese spitz! they seem like a lovely dog to own', 'likes': '1', 'dates': '1 year ago'}\n",
      "16  : {'username': '@EDavis-iw4zc', 'comment': 'Do they allow dog fighting in Japan ?', 'likes': '3', 'dates': '5 years ago'}\n",
      "17  : {'username': '@BlindGardener', 'comment': '@Belinda Babette good explanation', 'likes': '2', 'dates': '5 years ago (edited)'}\n",
      "18  : {'username': '@ghozisyaifullah254', 'comment': 'They allow it', 'likes': '', 'dates': '2 years ago'}\n",
      "19  : {'username': '@thetruecookie8115', 'comment': '️️️', 'likes': '2', 'dates': '5 years ago'}\n",
      "20  : {'username': '@inigomarcomartinez1855', 'comment': 'We have a Japanese spitz', 'likes': '1', 'dates': '4 years ago'}\n",
      "21  : {'username': '@zozotheblack', 'comment': 'Nice... please also see to me from India local breed..', 'likes': '', 'dates': '1 year ago'}\n",
      "22  : {'username': '@jerrybear6440', 'comment': 'Thank you....', 'likes': '1', 'dates': '2 years ago'}\n",
      "23  : {'username': '@aliimran5281', 'comment': \"U. Didn't show more\", 'likes': '', 'dates': '7 months ago'}\n",
      "24  : {'username': '@R4in_hehe463', 'comment': 'Dogs is so CUTEE ', 'likes': '1', 'dates': '3 years ago'}\n",
      "25  : {'username': '@urieltan3065', 'comment': 'i like the japanese spitz because i had that dog but it went missing i felt sad hope i can find her(her name is snow)', 'likes': '', 'dates': '3 years ago'}\n",
      "26  : {'username': '@truthtellerfreethinker7311', 'comment': 'Looks like a wolf and some like fox', 'likes': '', 'dates': '3 years ago'}\n",
      "27  : {'username': '@kkxtrufru', 'comment': 'Hachiko i love you so much', 'likes': '', 'dates': '3 years ago'}\n",
      "28  : {'username': '@animallifedaily7340', 'comment': 'So Beautiful', 'likes': '', 'dates': '3 years ago'}\n",
      "29  : {'username': '@oijosukeiliveinyourwalls5798', 'comment': 'Akita inu tosa', 'likes': '', 'dates': '3 years ago'}\n",
      "30  : {'username': '@VADELMAHILLO-tt9dx', 'comment': 'I WISHD ID HAD TOSA INU', 'likes': '', 'dates': '3 years ago'}\n",
      "31  : {'username': '@waffle3289', 'comment': 'I want them all', 'likes': '', 'dates': '3 years ago'}\n",
      "32  : {'username': '@kylebadboys4923', 'comment': 'I have japanese pets', 'likes': '', 'dates': '4 years ago'}\n",
      "33  : {'username': '@kitkatinthehat', 'comment': \"These look like the dogs that I've seen pictures of that are getting ready to go into slaughter, they eat their dogs over there.\", 'likes': '1', 'dates': '5 years ago (edited)'}\n",
      "34  : {'username': '@nyx2277', 'comment': 'The Japanese don’t eat dogs....', 'likes': '14', 'dates': '5 years ago'}\n",
      "35  : {'username': '@firaxolegirein9816', 'comment': 'Not all\\nIt is specialised in certain areas', 'likes': '', 'dates': '3 years ago'}\n",
      "> VIDEO TITLE: The 10 Most popular Japanese Dog Breeds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common import exceptions\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# Initialize the WebDriver\n",
    "from selenium.webdriver.chrome.service import Service  # Add this import\n",
    "\n",
    "def scrape(url):\n",
    "\n",
    "    # Note: Download and replace argument with path to the driver executable.\n",
    "    # Simply download the executable and move it into the webdrivers folder.\n",
    "    # Download and set up the ChromeDriver\n",
    "    chrome_driver_path = ChromeDriverManager().install()\n",
    "    service = Service(chrome_driver_path)  # Update this line\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Navigates to the URL, maximizes the current window, and\n",
    "    # then suspends execution for (at least) 5 seconds (this\n",
    "    # gives time for the page to load).\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        # Extract the elements storing the video title and\n",
    "        # comment section.\n",
    "        title = driver.find_element(\"xpath\",'//*[@id=\"title\"]/h1/yt-formatted-string').text\n",
    "        comment_section = driver.find_element(\"xpath\",'//*[@id=\"contents\"]')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        # Note: Youtube may have changed their HTML layouts for\n",
    "        # videos, so raise an error for sanity sake in case the\n",
    "        # elements provided cannot be found anymore.\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    # Scroll into view the comment section, then allow some time\n",
    "    # for everything to be loaded as necessary.\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", comment_section)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # Scroll all the way down to the bottom in order to get all the\n",
    "    # elements loaded (since Youtube dynamically loads them).\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down 'til \"next load\".\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load everything thus far.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # One last scroll just in case.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    \n",
    "    more_replies = driver.find_elements(\"xpath\",'//*[@id=\"more-replies\"]/yt-button-shape/button')\n",
    "    print(len(more_replies))\n",
    "    \n",
    "    print(more_replies)\n",
    "    for i in range(len(more_replies)):\n",
    "        print('click ', i)\n",
    "        driver.execute_script(\"arguments[0].click();\", more_replies[i])\n",
    "        # more_replies[i].click()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # BEGIN: Scroll to the top of the page\n",
    "    # Slowly scroll to the top of the page\n",
    "    scroll_pause_time = 0.1\n",
    "    current_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "    while current_position > 0:\n",
    "        driver.execute_script(\"window.scrollTo(0, arguments[0]);\", current_position - 50)\n",
    "        current_position -= 50\n",
    "        time.sleep(scroll_pause_time)\n",
    "    # END:\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        # Extract the elements storing the usernames and comments.\n",
    "        print('Extracting comments...')\n",
    "        username_elems = driver.find_elements(\"xpath\",'//*[@id=\"author-text\"]')\n",
    "        comment_elems = driver.find_elements(\"xpath\",'//*[@id=\"content-text\"]')\n",
    "        likes_elems = driver.find_elements(\"xpath\",'//*[@id=\"vote-count-middle\"]')\n",
    "        dates_elems = driver.find_elements(\"xpath\",'//*[@id=\"published-time-text\"]/a')\n",
    "        \n",
    "        for i in range(len(comment_elems)):\n",
    "            spans = comment_elems[i].find_elements(By.TAG_NAME, \"span\")\n",
    "            comment_text = \" \".join([span.text for span in spans])\n",
    "            comment_data = {\n",
    "                \"username\": username_elems[i].text,\n",
    "                \"comment\": comment_elems[i].text,\n",
    "                \"likes\": likes_elems[i].text,\n",
    "                \"dates\": dates_elems[i].text\n",
    "            }\n",
    "            print(i,\" :\",comment_data)\n",
    "            data.append(comment_data)\n",
    "    except exceptions.NoSuchElementException:\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    print(\"> VIDEO TITLE: \" + title + \"\\n\")\n",
    "\n",
    "    # with io.open('results.csv', 'w', newline='', encoding=\"utf-16\") as file:\n",
    "    #     writer = csv.writer(file, delimiter =\",\", quoting=csv.QUOTE_ALL)\n",
    "    #     writer.writerow([\"Username\", \"Comment\"])\n",
    "    #     for username, comment in zip(username_elems, comment_elems):\n",
    "    #         writer.writerow([username.text, comment.text])\n",
    "\n",
    "    # driver.close()\n",
    "   \n",
    "    return data\n",
    "\n",
    "scrapped_data = scrape(\"https://www.youtube.com/watch?v=Zn6-3gp8pKg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scrapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapped_data has been saved to scrapped_data_output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save scrapped_data to a JSON file\n",
    "with open('scrapped_data_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(scrapped_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"scrapped_data has been saved to scrapped_data_output.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
